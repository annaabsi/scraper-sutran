name: scraper-daily

on:
  # Triggers the workflow on push or pull request events but only for the main branch
  push:
    branches: [ main ]
  schedule:
    - cron: '0 2,4,12,14,16,18,21,23 * * *' # runs at 2,4,12,14,16,18,21,23 UTC everyday

jobs:
  scraper:
    runs-on: ubuntu-20.04
    steps:

      - name: checkout repo content
        uses: actions/checkout@v2 # checkout the repository content to github runner

      - name: setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9.7' # install the python version needed

      - name: execute my python script
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          python scraper.py
      - name: commit my files
        run: |
          git pull
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add -A
          git commit --allow-empty -m "update data daily sutran" -a
      - name: push my changes
        uses: ad-m/github-push-action@v0.6.0
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: main

name: push-file-another-repo

on: push

jobs:
  copy-file:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout
      uses: actions/checkout@v2

    - name: Pushes test file
      uses: dmnemec/copy_file_to_another_repo_action@main
      env:
        API_TOKEN_GITHUB: ${{ secrets.SCRAPER_SUTRAN_PAT }}
      with:
        source_file: 'resultados_flourish.csv'
        destination_repo: 'annaabsi/sutran-data'
        user_email: 'anna.absi@gmail.com'
        user_name: 'annaabsi'
        commit_message: 'actualizando datos'